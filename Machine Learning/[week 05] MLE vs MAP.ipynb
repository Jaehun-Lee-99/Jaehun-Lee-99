{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **[Week 5] Maximum Likelihood Estimation (MLE) vs Maximum A Posteriori (MAP)**\n",
    "\n",
    "In this practice session, we will cover the following:\n",
    "- Understand the basic concept of maximum likelihood estimation (MLE) and maximum a posteriori (MAP)\n",
    "- Observe how the priors affect the results in MAP with the simple coin toss example\n",
    "\n",
    "**[Important]** \\\\\n",
    "The results of the exercises should be included in your weekly report for this practice session.\n",
    "The weekly report for this session should be submitted to KLMS by this weekend. No late submission would be accepted.\n",
    "\n",
    "### Recap. What are MLE and MAP?\n",
    "##### 1) Objective\n",
    "We sample parametrized i.i.d. random variables $\\{x_i\\}$ and estimate the parameters from samples.\n",
    "##### 2) Likelihood\n",
    "If we denote samples to $x=\\{x_i\\}$ and parameters to $\\theta$, then likelihood $L(x|\\theta)=\\prod_i L(x_i|\\theta)$, where $L(x_i|\\theta)$ is either PMF (discrete) or PDF (continuous). We can calculate this because we assume a certain distribution without knowledge of parameter values.\n",
    "##### 3) MLE\n",
    "We consider $L(x|\\theta)$ as a function of $\\theta$ and find $\\theta$ s.t. maximizes it; we can analytically derive it using derivatives or just numerically derive it using computer softwares such as Python (we will do this).\n",
    "##### 4) MAP\n",
    "In the Bayesian approach, we consider parameters as random variables. We want to derive $p(\\theta|x)$, which is called posterior because it is the distribution after observing the data. By Bayes' theorem, $p(\\theta|x)=\\frac{p(x|\\theta)p(\\theta)}{p(x)}$. Observe that $p(x|\\theta) \\propto L(x|\\theta)$ and $p(x)$ is constant with respect to $\\theta$ although we cannot derive it easily. Hence, $p(\\theta|x)\\propto L(x|\\theta)p(\\theta)$ so that a maximizer $\\theta^{\\star}:=\\arg\\max_{\\theta}p(\\theta|x)=\\arg\\max_{\\theta}L(x|\\theta)p(\\theta)$, and we call such maximizer MAP and we call $p(\\theta)$ prior because it is the distribution before data observation. As we can easily guess, if the prior is uniform then MAP coincides with MLE.\n",
    "##### 5) In a coin toss case\n",
    "For coin toss, we assume the i.i.d. tosses, which means that we assume i.i.d. Bernouilli distribution $\\text{Bern}(p)$ ($p$ is considered as a parameter, which takes the role of $\\theta$ for general case). while the likelihood is $p^x (1-p)^{(n-x)}$ when the heads appeared x times out of n tosses. Note that $L(x|p)\\propto \\text{Beta}(p;\\alpha, \\beta)$, where $\\alpha=x+1$ and $\\beta=n-x+1$ because $\\text{Beta}(p;\\alpha, \\beta)=\\frac{1}{B(\\alpha, \\beta)}p^{\\alpha-1}(1-p)^{\\beta-1}$. Also, the product of PDF of two beta distributions is also beta PDF. <br>\n",
    "We cannot know the prior, but we may **believe in** certain distributions, like Gaussian, beta, truncated uniform, $\\cdots$. In this session, our belief is that the coin is fair or close to fair, which means that $\\hat{p}$, which is the estimate of $p$ is 0.5, thus the mode of the prior is 0.5.\n",
    "##### 6) Analytic vs numerical approach to find MLE or MAP\n",
    "Analytic approach: likelihood and posterior are closed forms for our cases-take derivative (or take logarithm first) to find extrema and check if they are global maxima <br>\n",
    "Numerical approach: since $0\\leq p\\leq 1$, we equally slice $[0,1]$ into certain number of pieces (10000 for our case) and get likelihood or posterior for each p value and find what p value achieves maximum among them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                  # Tool for calculations and arrays\n",
    "from scipy.stats import bernoulli, beta, norm       # Tool for handling probability distributions\n",
    "import matplotlib.pyplot as plt                     # Tool for plot and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define Key Functions\n",
    "\n",
    "In this section, we define functions used below. Here are many exercises and you have to implement correctly for "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1. p and coin toss\n",
    "\n",
    "First define **p**, an array consists of possible p values from 0 to 1, interval 0.0001 (=1/10000). This is crucial for numerical derivation of MLE and MAP.\n",
    "\n",
    "**coin_toss** is a function that <br>\n",
    "input: {n: number of coin tosses, p_real: the exact value of p in Bernoulli distribution, seed: to fix the result}, <br>\n",
    "output: a series of coin toss result and the number of heads. <br>\n",
    "\n",
    "You may specify the seed value for reproducibility, or just remain it blank to make the result different for each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=np.linspace(0, 1, num=10001)\n",
    "\n",
    "def coin_toss(n, p_real, seed=None): \n",
    "    # Generate n Bernoulli samples (1 for head, 0 for tail)\n",
    "    result = bernoulli.rvs(p_real, random_state=seed, size=n)\n",
    "    \n",
    "    # Count the number of heads\n",
    "    num_heads = result.sum()\n",
    "    \n",
    "    return result, num_heads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2. MLE\n",
    "\n",
    "**Exercise 1.** Implement `likelihood`, which has <br>\n",
    "input: {x: number of heads, n: number of tosses, p: an 1D array defined above}, <br>\n",
    "output: An 1D array that outputs likelihood for each element in p. \n",
    "\n",
    "Note that the likelihood concerns the **order** of the coin tosses, which means that (H, T) is a different event from (T, H) while x and n are the same. <br> \n",
    "You can easily find the formula in above explanation. <br>\n",
    "(Hint: although p is an array, in below code we can consider it as a single element in the sense that the code looks identitcal.)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(x, n, p):\n",
    "    ########## implement here ##########\n",
    "    \n",
    "    \n",
    "    ####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.** Implement `calculate_MLE`, which has <br>\n",
    "Implement the function **calculate_MLE** that <br>\n",
    "input: {x, n, p}, <br>\n",
    "output: MLE, which is in $[0,1]$. <br>\n",
    "\n",
    "Use **numerical approach** for this function. You may want to use **likelihood**.  <br>\n",
    "(Hint: `np.argmax(array)` outputs the index that has the maximum entry value if an **array** is 1D (bool, int, or <U>float</U>) array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_MLE(x, n, p):\n",
    "    ########## implement here ##########\n",
    "    \n",
    "    \n",
    "    ####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-3. MAP\n",
    "\n",
    "**prior** is a function that <br>\n",
    "input: {p, mode: the type of distribution, param_1, param_2: parameters for beta and Gaussian distribution}, <br>\n",
    "output: An 1D array that outputs the prior probability for each p value.\n",
    "\n",
    "mode: {'uniform', 'beta' ,'Gaussian'} <br>\n",
    "If mode='uniform', it uses uniform distribution on $[0,1]$. <br>\n",
    "If mode='beta', it uses beta distribution, $\\text{Beta}(p;\\alpha,\\beta)$ with $\\alpha=\\text{param}\\_1$, $\\beta=\\text{param}\\_2$.\n",
    "If mode='Gaussian', it uses, Gaussian distribution, $\\mathcal{N}(p;\\mu,\\sigma^2)$ with $\\mu=\\text{param}\\_1$, $\\sigma=\\text{param}\\_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior(p, mode, param_1=1, param_2=1):\n",
    "    if mode == 'uniform':\n",
    "        return 1.0  # Uniform prior\n",
    "    elif mode == 'beta':\n",
    "        return beta.pdf(p, param_1, param_2)  # Beta prior\n",
    "    elif mode == 'Gaussian':\n",
    "        return norm.pdf(p, param_1, param_2)  # Gaussian prior    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.** Implement `unnormalized_posterior`, which has <br>\n",
    "input: {x, n, p}, <br>\n",
    "output: An 1D array that outputs unnormalized posterior for each element in p. \n",
    "\n",
    "See **Recap** for formula. Note that an elementwise product of two equal-sized arrays can be done by * (product) operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalized_posterior(x, n, p, mode, param_1=1, param_2=1):\n",
    "    ########## implement here ##########\n",
    "    \n",
    "    \n",
    "    ####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4.** Implement `calculate_MAP`, which has <br>\n",
    "input: {x, n, p, mode, param_1, param_2}, <br>\n",
    "output: MAP, which is in $[0,1]$.\n",
    "\n",
    "It would be very helpful to implement this if you see **Exercise 2**. Also, you may want to use **unnormalized_posterior**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_MAP(x, n, p, mode, param_1=1, param_2=1):\n",
    "    ########## implement here ##########\n",
    "    \n",
    "    \n",
    "    ####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Small number of fair coin tosses\n",
    "\n",
    "In this section, we will see the nature of MLE and MAP, especially the impact of the choice of prior, when $n$ is small.\n",
    "\n",
    "#### 3-1. Coin toss situation and result\n",
    "\n",
    "The exact p, p_real is 0.5 and the number of tosses $n=10$. We fix the case that only three out of ten coin tosses got heads by seed, but you may change the seed or just erase the seed for variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "p_real = 0.5\n",
    "seed = 11\n",
    "\n",
    "result, x = coin_toss(n, p_real, seed)\n",
    "\n",
    "print('The result is:')\n",
    "print(result)\n",
    "print('The number of heads is', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-2. MLE estimation\n",
    "\n",
    "We use MLE for the estimation of $p$. For the numerical method, we just use the above **calculate_MLE** function in task 1. <br>\n",
    "For the analytic method, note that by taking the logarithm of likelihood and taking the derivative, we can easily get that **p_mle=x/n**. <br>\n",
    "We check if both coincide and plot the likelihood function and MLE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MLE value numerically\n",
    "p_mle_1 = calculate_MLE(x, n, p)\n",
    "print('MLE of this coin toss is', p_mle_1)\n",
    "\n",
    "# Check if the above value coincides to that by analytic approach\n",
    "if p_mle_1 == x / n:\n",
    "    print('MLE by analytic approach is', x / n, 'which coincides with the result from the numerical approach.')\n",
    "else:\n",
    "    print('MLE by analytic approach is', x / n, 'which does not coincide with the result from the numerical approach.')\n",
    "\n",
    "# plot likelihood function and MLE\n",
    "plt.plot(p, likelihood(x, n, p))\n",
    "plt.axvline(x=p_mle_1, color='r', linestyle='--', label='MLE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-3. MAP estimation (1)\n",
    "\n",
    "We use MAP for estimation now with **calculate_MAP** function. For each case, we compare MAP with MLP calculated above. \n",
    "\n",
    "At first we use uniform prior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MAP with uniform prior\n",
    "p_map_1_1 = calculate_MAP(x, n, p, mode='uniform')\n",
    "\n",
    "# Print results for uniform prior\n",
    "print('MAP of this coin toss with a uniform prior is', p_map_1_1)\n",
    "\n",
    "if p_map_1_1 == p_mle_1:\n",
    "    print('The MLE is', p_mle_1, 'which coincides with the MAP.')\n",
    "else:\n",
    "    print('The MLE is', p_mle_1, 'which does not coincide with the MAP.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-4. MAP estimation (2)\n",
    "\n",
    "Next, we use nonuniform priors. Especially, we use beta and Gaussian priors, which are used frequently for cases like ours. <br>\n",
    "We believe that the coin is **fair**, which means p_real is 0.5.\n",
    "Use $\\text{Beta}(20, 20)$ and $\\mathcal{N}(0.5, 0.05^2). Both has mode 0.5 and symmetric bell shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on, see the PDFs of such two priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Beta(20, 20)\n",
    "plt.plot(p, beta.pdf(p, 20, 20), color='b', label='Beta(20, 20)')\n",
    "\n",
    "# Plot N(0.5, 0.05^2); clipped but not significant\n",
    "plt.plot(p, norm.pdf(p, 0.5, 0.05), color='r', label='$\\mathcal{N}(0.5, 0.05^2)$')\n",
    "\n",
    "# Labels and Legend\n",
    "plt.xlabel('p')\n",
    "plt.ylabel('pdf')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then calculate MAP with such priors. Compare two MAPs and MLE. Also observe that how much the PDF of the prior concentrated near 0.5 (you can see it right above) affects MAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MAP with Beta(20, 20) prior\n",
    "p_map_1_2 = calculate_MAP(x, n, p, mode='beta', param_1=20, param_2=20)\n",
    "\n",
    "# Calculate MAP with N(0.5, 0.05^2) prior\n",
    "p_map_1_3 = calculate_MAP(x, n, p, mode='Gaussian', param_1=0.5, param_2=0.05)\n",
    "\n",
    "# Print results for Beta(20, 20) prior\n",
    "print('MAP of this coin toss with Beta(20, 20) prior is', p_map_1_2)\n",
    "if p_map_1_2 == p_mle_1:\n",
    "    print('MLE is', p_mle_1, 'which coincides with MAP.')\n",
    "else:\n",
    "    print('MLE is', p_mle_1, 'which does not coincide with MAP.')\n",
    "\n",
    "# Print results for N(0.5, 0.05^2) prior\n",
    "print('MAP of this coin toss with N(0.5, 0.05^2) prior is', p_map_1_3)\n",
    "if p_map_1_3 == p_mle_1:\n",
    "    print('MLE is', p_mle_1, 'which coincides with MAP.')\n",
    "else:\n",
    "    print('MLE is', p_mle_1, 'which does not coincide with MAP.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-5. Visualization (1)\n",
    "\n",
    "To reduce the repetition of lengthy codes, we predefine the main part. <br>\n",
    "This graph consists of <br>\n",
    "points: p_real (black), MLE (yellow), mode of prior (red), MAP (cyan) (dashed vertical lines) <br>\n",
    "graphs: likelihood (blue), prior (green), posterior (magenta) (curves; maximum value is normalized to 1 for easier comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_MAP(x, n, p, mode, param_1, param_2, p_mle, p_map, prior_mode, corrected=False):\n",
    "\n",
    "    # Exact p value\n",
    "    plt.axvline(x=p_real, color='k', linestyle='--', label='True p value')\n",
    "    \n",
    "    # Likelihood graph\n",
    "    likelihood_values = likelihood(x, n, p) / likelihood(x, n, p_mle)\n",
    "    plt.plot(p, likelihood_values, color='b', label='Likelihood')\n",
    "    plt.axvline(x=p_mle, color='y', linestyle='--', label='MLE')\n",
    "    \n",
    "    # Prior graph\n",
    "    prior_values = prior(p, mode=mode, param_1=param_1, param_2=param_2) / \\\n",
    "                   prior(prior_mode, mode=mode, param_1=param_1, param_2=param_2)\n",
    "    if corrected:\n",
    "        prior_label = 'beta (corrected) prior'\n",
    "    else:\n",
    "        prior_label = f'{mode} prior'\n",
    "    plt.plot(p, prior_values, color='g', label=prior_label)\n",
    "    plt.axvline(x=prior_mode, color='r', linestyle='--', label=f'Mode of {prior_label}')\n",
    "    \n",
    "    # Posterior graph\n",
    "    posterior_values = unnormalized_posterior(x, n, p, mode=mode, param_1=param_1, param_2=param_2) / \\\n",
    "                       unnormalized_posterior(x, n, p_map, mode=mode, param_1=param_1, param_2=param_2)\n",
    "    if corrected:\n",
    "        posterior_label = 'Posterior with beta (corrected) prior'\n",
    "    else:\n",
    "        posterior_label = f'Posterior with {mode} prior'\n",
    "    plt.plot(p, posterior_values, color='m', label=posterior_label)\n",
    "    plt.axvline(x=p_map, color='c', linestyle='--', label=f'MAP with {posterior_label}')\n",
    "    \n",
    "    # Graph visualization\n",
    "    plt.legend(fontsize='8', framealpha=0.5)\n",
    "    plt.title(f'{posterior_label}')\n",
    "    plt.xlabel('p')\n",
    "    plt.ylabel('Normalized Probability / Function Value')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-6. Visualization (2)\n",
    "\n",
    "Now we see the full graph. Note that p_real (black) is invisible because it coincides to mode of prior (red) and thus overwritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graph of MAP with beta prior\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "plot_MAP(x, n, p, mode='beta', param_1=20, param_2=20, p_mle=p_mle_1, p_map=p_map_1_2, prior_mode=0.5)\n",
    "\n",
    "\n",
    "# Plot graph of MAP with Gaussian prior\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "plot_MAP(x, n, p, mode='Gaussian', param_1=0.5, param_2=0.05, p_mle=p_mle_1, p_map=p_map_1_3, prior_mode=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Large number of fair coin tosses\n",
    "\n",
    "In this section, we will see the nature of MLE and MAP, especially the impact of the choice of prior, when $n$ is large. We focus on the changes compare to **3**. <br>\n",
    "We use same priors except for uniform because by both analytically and numerically, we have already seen that MAP with uniform prior is equivalent to MLE.\n",
    "\n",
    "#### 4-1. Coin toss situation and result\n",
    "\n",
    "p_real is still 0.5 and the number of tosses $n$ is increased from 10 to 100 compared to **3**. We do not set the seed and feel free to execute repeatedly (before moving on to **5** or later) to observe diverse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "p_real = 0.5\n",
    "seed = None # no seed for this case\n",
    "\n",
    "result, x = coin_toss(n, p_real, seed)\n",
    "\n",
    "print('The result is:')\n",
    "print(result)\n",
    "print('The number of heads is', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-2. MLE and MAP estimation\n",
    "\n",
    "We perform MLE and MAP with two nonuniform priors used in **3-4**. Observe the different behavior, especially how much the MAPs are closer to 0.5 than MLE compared to those in **3-4**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MLE\n",
    "p_mle_2 = calculate_MLE(x, n, p)\n",
    "print('MLE of this coin toss is', p_mle_2)\n",
    "\n",
    "# Calculate MAP with Beta(20, 20) prior\n",
    "p_map_2_2 = calculate_MAP(x, n, p, mode='beta', param_1=20, param_2=20)\n",
    "print('MAP of this coin toss with Beta(20, 20) prior is', p_map_2_2)\n",
    "\n",
    "# Calculate MAP with N(0.5, 0.05^2) prior\n",
    "p_map_2_3 = calculate_MAP(x, n, p, mode='Gaussian', param_1=0.5, param_2=0.05)\n",
    "print('MAP of this coin toss with N(0.5, 0.05^2) prior is', p_map_2_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-3. Visualization\n",
    "\n",
    "The settings are as same as **3-6**. Find the differences from **3-6**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graph of MAP with beta prior\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "plot_MAP(x, n, p, mode='beta', param_1=20, param_2=20, p_mle=p_mle_2, p_map=p_map_2_2, prior_mode=0.5)\n",
    "\n",
    "\n",
    "# Plot graph of MAP with Gaussian prior\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "plot_MAP(x, n, p, mode='Gaussian', param_1=0.5, param_2=0.05, p_mle=p_mle_2, p_map=p_map_2_3, prior_mode=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Medium number of unfair coin tosses\n",
    "\n",
    "In this section, we will see the nature of MLE and MAP, especially the impact of the choice of prior, when $n$ is medium and the coin is **unfair**. <br>\n",
    "The settings other than n, p_real, and seed are identical to **4**.\n",
    "\n",
    "#### 5-1. Coin toss situation and result\n",
    "\n",
    "From now on, the coin is unfair; p_real is now increased to 0.7 and the number of tosses $n$ is 20. We fix the case that thirteen out of twenty coin tosses got heads by seed, but you may change the seed or just erase the seed for variation. However, if so, it does not match to prior correction in **6**, so keep in mind or if you want to link it, then change the parameters in **6** as explained there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "p_real = 0.7\n",
    "seed = 6\n",
    "\n",
    "result, x = coin_toss(n, p_real, seed)\n",
    "\n",
    "print('The result is:')\n",
    "print(result)\n",
    "print('The number of heads is', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-2. MLE and MAP estimation\n",
    "\n",
    "We perform MLE and MAP with two nonuniform priors used in **3-4** and **4-2**. Observe the different behavior due to the wrong belief reflected to priors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MLE\n",
    "p_mle_3 = calculate_MLE(x, n, p)\n",
    "print('MLE of this coin toss is', p_mle_3)\n",
    "\n",
    "# Calculate MAP with Beta(20, 20) prior\n",
    "p_map_3_2 = calculate_MAP(x, n, p, mode='beta', param_1=20, param_2=20)\n",
    "print('MAP of this coin toss with Beta(20, 20) prior is', p_map_3_2)\n",
    "\n",
    "# Calculate MAP with N(0.5, 0.05^2) prior\n",
    "p_map_3_3 = calculate_MAP(x, n, p, mode='Gaussian', param_1=0.5, param_2=0.05)\n",
    "print('MAP of this coin toss with N(0.5, 0.05^2) prior is', p_map_3_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-3. Visualization\n",
    "\n",
    "The settings are as same as **3-6** and **4-3**. Find the differences from **3-6** and **4-3**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graph of MAP with beta prior\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "plot_MAP(x, n, p, mode='beta', param_1=20, param_2=20, p_mle=p_mle_3, p_map=p_map_3_2, prior_mode=0.5)\n",
    "\n",
    "\n",
    "# Plot graph of MAP with Gaussian prior\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "plot_MAP(x, n, p, mode='Gaussian', param_1=0.5, param_2=0.05, p_mle=p_mle_3, p_map=p_map_3_3, prior_mode=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Large number of unfair coin tosses with prior correction\n",
    "\n",
    "In this section, we will see the nature of MLE and MAP, especially the impact of the choice of prior, when $n$ is large and the coin is **unfair**. <br>\n",
    "The settings other than n, p_real, and seed are similar to **4** and **5** but there is one important difference: we added one more MAP with corrected prior.\n",
    "\n",
    "Corrected prior is made by the observation in **5**. Since in **5** there were 13 heads and 7 tails, we use its likelihood as prior after normalization. <br>\n",
    "Then, our prior becomes $\\text{Beta}(14, 8)$. If you want not to set the seed in **5** and link the observations here, then use this formula for corrected prior: $\\text{Beta}(x-1,n-x-1)$ and change the mode of prior to x/n in **6-3**.\n",
    "\n",
    "#### 6-1. Coin toss situation and result\n",
    "\n",
    "p_real is still 0.7 and the number of tosses $n$ is increased from 20 to 100. We do not set the seed and feel free to execute repeatedly to observe diverse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "p_real = 0.7\n",
    "seed = None\n",
    "\n",
    "result, x = coin_toss(n, p_real, seed)\n",
    "\n",
    "print('The result is:')\n",
    "print(result)\n",
    "print('The number of heads is', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-2. MLE and MAP estimation\n",
    "\n",
    "We perform MLE and MAP with two nonuniform priors used in **3-4** and **4-2** plus the corrected prior. Observe the different behaviors among MAPs with different prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MLE\n",
    "p_mle_4 = calculate_MLE(x, n, p)\n",
    "print('MLE of this coin toss is', p_mle_4)\n",
    "\n",
    "# Calculate MAP with Beta(20, 20) prior (uncorrected)\n",
    "p_map_4_2 = calculate_MAP(x, n, p, mode='beta', param_1=20, param_2=20)\n",
    "print('MAP of this coin toss with Beta(20, 20) prior is', p_map_4_2)\n",
    "\n",
    "# Calculate MAP with N(0.5, 0.05^2) prior\n",
    "p_map_4_3 = calculate_MAP(x, n, p, mode='Gaussian', param_1=0.5, param_2=0.05)\n",
    "print('MAP of this coin toss with N(0.5, 0.05^2) prior is', p_map_4_3)\n",
    "\n",
    "# Calculate MAP with Beta(14, 8) prior (corrected)\n",
    "p_map_4_4=calculate_MAP(x, n, p, mode='beta', param_1=14, param_2=8) \n",
    "print('MAP of this coin toss with Beta(14,8) (corrected) prior is', p_map_4_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-3. Visualization\n",
    "\n",
    "See the graphs. Focus on how the corrected prior impact on MAP by comparing it to MAPs with different priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graph of MAP with beta prior (uncorrected)\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "plot_MAP(x, n, p, mode='beta', param_1=20, param_2=20, p_mle=p_mle_4, p_map=p_map_4_2, prior_mode=0.5)\n",
    "\n",
    "# Plot graph of MAP with Gaussian prior\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "plot_MAP(x, n, p, mode='Gaussian', param_1=0.5, param_2=0.05, p_mle=p_mle_4, p_map=p_map_4_3, prior_mode=0.5)\n",
    "\n",
    "# Plot graph of MAP with beta prior (corrected)\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "plot_MAP(x, n, p, mode='beta', param_1=14, param_2=8, p_mle=p_mle_4, p_map=p_map_4_4, prior_mode=0.65, corrected=True) # mode of Beta(14,8)=(14-1)/(14+8-2)=0.65\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
